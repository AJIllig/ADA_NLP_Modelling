{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Analysis Assignment 2: PreProcessing\n",
    "\n",
    "#### Enviroment: Python 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# General\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from time import perf_counter    # cell runtime\n",
    "from natsort import natsorted    # intuitive sorting and renaming of variables\n",
    "from itertools import chain      # used in concatenation function\n",
    "# import winsound                  # play a sound (windows only)\n",
    "\n",
    "# Tokenizing\n",
    "import nltk.data                                                                    # punkt sentence tokenizer\n",
    "from nltk.tokenize import PunktSentenceTokenizer, RegexpTokenizer, word_tokenize    # word tokenizers\n",
    "from nltk.corpus import wordnet                                                     # parts of speech tagging\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer                              # lemming and stemming\n",
    "\n",
    "# Stopword Removal\n",
    "import string                        # list of punctuation\n",
    "from nltk.corpus import stopwords    # use nltk short list of stopwords (unused)\n",
    "from nltk.probability import *       # token frequency distributions (FreqDist())\n",
    "\n",
    "# Vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start timer\n",
    "t_start = perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Defined Functions\n",
    "See Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_concat(a_list):\n",
    "    '''\n",
    "    concatenates the values in a list\n",
    "    '''\n",
    "    return list(chain.from_iterable(a_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Text Files into Newline separated Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Test Docs Location\n",
    "target_folder = Path.home().joinpath('DropBox', \n",
    "                                     'Monash_Uni', \n",
    "                                     'FIT5149 Applied Data Analysis', \n",
    "                                     'Assessment 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the training documents\n",
    "target_file = target_folder.joinpath('training_docs.txt')\n",
    "\n",
    "with open(target_file, mode='r', encoding='utf-8') as data_file:\n",
    "    tr_docs = data_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the training class labels\n",
    "target_file = target_folder.joinpath('training_labels_final.txt')\n",
    "\n",
    "with open(target_file, encoding='utf-8') as data_file:\n",
    "    tr_labs = data_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test documents\n",
    "target_file = target_folder.joinpath('testing_docs_shuffle.txt')\n",
    "\n",
    "with open(target_file, encoding='utf-8') as data_file:\n",
    "    test_docs = data_file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Document Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train: Create a dictionary of document id : content text\n",
    "tr_docs_dict = {}\n",
    "for line in tr_docs:\n",
    "    line = line.strip()\n",
    "    if (line != '' and line.lower() != 'eod'):            # exclude empty and end-of-document lines\n",
    "        if bool(re.match(r'^(ID)', line)):                # identify lines starting with 'ID'\n",
    "            id_k = re.findall(r'(?<=ID ).*$', line)[0]    # get the document id\n",
    "            text = []                                     # empty list to hold document contents\n",
    "        else:\n",
    "            t = re.findall(r'(?<=TEXT ).*$', line)[0]     # get the document contents past the 'TEXT' signifier\n",
    "            text.append(t.lower())                        # normalise to lowercase\n",
    "    tr_docs_dict[id_k] = text                             # create a dictionary of document id key : document content list value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train: Create a dictionary of document id : class label\n",
    "tr_labs_dict = {}\n",
    "for line in tr_labs:\n",
    "    line = line.strip()\n",
    "    id_k = re.findall('(?:\\S+)+', line)    # list the terms\n",
    "    tr_labs_dict[id_k[0]] = id_k[1]        # create dictionary of document id : class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test: Create a dictionary of document id : content text\n",
    "test_docs_dict = {}\n",
    "for line in test_docs:\n",
    "    line = line.strip()\n",
    "    if (line != '' and line.lower() != 'eod'):            # exclude empty and end-of-document lines\n",
    "        if bool(re.match(r'^(ID)', line)):                # identify lines starting with 'ID'\n",
    "            id_k = re.findall(r'(?<=ID ).*$', line)[0]    # get the document id\n",
    "            text = []                                     # empty list to hold document contents\n",
    "        else:\n",
    "            t = re.findall(r'(?<=TEXT ).*$', line)[0]     # get the document contents past the 'TEXT' signifier\n",
    "            text.append(t.lower())                        # normalise to lowercase\n",
    "    test_docs_dict[id_k] = text                             # create a dictionary of document id key : document content list value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame.from_dict(test_docs_dict, orient='index', columns=['Contents'])\n",
    "test_df.reset_index(inplace=True)\n",
    "test_df.rename(columns = {'index':'Doc'}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training labels dataframe\n",
    "tr_labs_df = pd.DataFrame.from_dict(tr_labs_dict, orient='index', columns=['Class'])\n",
    "\n",
    "# Training contents dataframe\n",
    "tr_docs_df = pd.DataFrame.from_dict(tr_docs_dict, orient='index', columns=['Contents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined dataframe\n",
    "tr_df = pd.concat([tr_labs_df, tr_docs_df], axis=1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add category column\n",
    "tr_df['Category'] = tr_df['Class'].apply(lambda x: int(x[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename and Rearrange the columns\n",
    "tr_df.rename(columns = {'index':'Doc'}, inplace=True)   \n",
    "cols = tr_df.columns.tolist()\n",
    "cols.insert(1, cols.pop(cols.index('Category')))\n",
    "tr_df = tr_df.reindex(columns= cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of training documents (needed later for getting percentage of removed empty docs)\n",
    "num_tr_docs = tr_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the Training Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punkt sentence tokeniser\n",
    "sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "# sent_tokenizer = PunktSentenceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to convert POS tags to wordnet tags\n",
    "# The code in this cell is adapted from the following website\n",
    "# http://stackoverflow.com/questions/15586721/wordnet-lemmatization-and-pos-tagging-in-python\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate tokenisation function\n",
    "def bespoke_tokenizer(text):\n",
    "    # identify sentences\n",
    "    sents = sent_tokenizer.tokenize(text.strip())\n",
    "    # tokenize the sentences\n",
    "    toks = [word_tokenize(i) for i in sents] \n",
    "    # tag parts of speech\n",
    "    tb_pos = list_concat([nltk.pos_tag(j) for j in toks])\n",
    "    # convert treebank tags to wordnet tags\n",
    "    wd_pos  = [(pair[0], get_wordnet_pos(pair[1])) for pair in tb_pos]\n",
    "    # derive lemmas\n",
    "    lems = [(lemmatizer.lemmatize(pair[0]), pair[1]) for pair in wd_pos]\n",
    "    # return tokens\n",
    "    return [k[0] for k in lems]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add empty column to dataframes\n",
    "tr_df['Tokens'] = ''\n",
    "test_df['Tokens'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run the tokenizer and print out run checks\n",
    "def run_tokenizer(df):\n",
    "    # get run time\n",
    "    t0 = perf_counter()  \n",
    "    # tokenize\n",
    "    for item in df.itertuples():\n",
    "        df.at[item.Index, 'Tokens'] = bespoke_tokenizer(item.Contents)\n",
    "        if (item[0] % 1000 == 0):\n",
    "            t1 = perf_counter()\n",
    "            elapsed_time = t1 - t0   \n",
    "            print('Still running! It has been %.1f mins' % ((elapsed_time)/60))\n",
    "    t1 = perf_counter()\n",
    "    elapsed_time = t1 - t0   \n",
    "    print('Total Elapsed time: %.1f mins' % ((elapsed_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the dataframe - only run this to recreate the pickle file if needed -  warning: long run time\n",
    "# run_tokenizer(tr_df)      3 ~204 min\n",
    "# run_tokenizer(test_df)    # ~50 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the better way to run the tokenizer but doesn't include print statements of periodioc runtime\n",
    "# %%time\n",
    "# tr_df['Tokens'] = tr_df['Contents'].apply(bespoke_tokenizer)\n",
    "# test_df['Tokens'] = test_df['Contents'].apply(bespoke_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned and tokenized dataframes to pickle (since running the tokenization takes so long)\n",
    "# tr_df.to_pickle('tokenised_tr_df.pkl')\n",
    "# test_df.to_pickle('tokenised_test_df.pkl')\n",
    "\n",
    "# read the pickled dataframes\n",
    "tr_df = pd.read_pickle(target_folder.joinpath('tokenised_tr_df.pkl'))\n",
    "test_df = pd.read_pickle(target_folder.joinpath('tokenised_test_df.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stopwords, Hapaxes, and Empty Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Set of Freestanding Punctuation, Contractions, and Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of punctuation to remove\n",
    "punct = set(string.punctuation)\n",
    "punct.update([\"''\",\"``\",\"...\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get set of very common stopwords\n",
    "# csw = set(stopwords.words(\"english\"))    # nltk's list of stopwords (short)\n",
    "csw = []\n",
    "with open(target_folder.joinpath('stopwords_en.txt')) as f:\n",
    "    csw = set(f.read().splitlines()) # list of stopwords (long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create set of contraction words\n",
    "target_file = target_folder.joinpath('wiki_list_contractions.txt')\n",
    "\n",
    "with open(target_file, encoding='utf-8') as data_file:\n",
    "    wlc = data_file.read()\n",
    "\n",
    "tokenizer = RegexpTokenizer(r\"\\s+\", gaps=True) # (\\s means any whitespace character (\\t\\n\\r\\f\\v))\n",
    "contractions = set(tokenizer.tokenize(wlc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get set of tokens in the test dataset taht are not in the training dataset\n",
    "all_tr_tokens = set(list_concat(tr_df['Tokens'].tolist()))\n",
    "all_test_tokens = set(list_concat(test_df['Tokens'].tolist()))\n",
    "diff = all_test_tokens.difference(all_tr_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional stopwords\n",
    "other = {'ha', 'wa'}    # lemmatizer converts 'has' to 'ha' and 'was' to 'wa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete set of stopwords\n",
    "stopwords_1 = csw.union(contractions, punct, diff, other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to keep an item in a list if it is not found in a reference\n",
    "def remove_stopwords(text, stopwords):\n",
    "    return [token for token in text if token not in stopwords]    # list and set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Remove stopwords\n",
    "tr_df['Tokens'] = tr_df['Tokens'].apply(remove_stopwords, args=(stopwords_1,))\n",
    "test_df['Tokens'] = test_df['Tokens'].apply(remove_stopwords, args=(stopwords_1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming\n",
    "* stem to target all the words missed by the lemmatizer \n",
    "* even if the stemmed word is wrong (ex. bushfires and bushfire $\\rightarrow$ bushfir) it shouldn't matter as long as it's consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Stem\n",
    "tr_df['Tokens'] = tr_df['Tokens'].apply(lambda x : [ps.stem(y) for y in x])\n",
    "test_df['Tokens'] = test_df['Tokens'].apply(lambda x : [ps.stem(y) for y in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Hapaxes\n",
    "Reduces vectorization time significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of all tokens in the corpus\n",
    "all_words = list_concat(tr_df['Tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get frequency distribution of tokens\n",
    "freq_dist = FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hapaxes\n",
    "haps = set(freq_dist.hapaxes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove hapaxes\n",
    "tr_df['Tokens'] = tr_df['Tokens'].apply(remove_stopwords, args=(haps,))\n",
    "test_df['Tokens'] = test_df['Tokens'].apply(remove_stopwords, args=(haps,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(haps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Empty Docs from the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove docs with k tokens\n",
    "k = 0\n",
    "tr_df = tr_df[tr_df['Tokens'].map(lambda d: len(d)) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of docs removed\n",
    "'{}%'.format(round(100*(num_tr_docs-tr_df.shape[0])/num_tr_docs, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of removed indices\n",
    "rm_inds = set(range(0,num_tr_docs-1)) - set(tuple(tr_df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate Tokens \n",
    "In preparation to feed to the tf-idf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the tokens for each document\n",
    "tr_df['Final_Tokens'] = tr_df['Tokens'].str.join(' ')\n",
    "test_df['Final_Tokens'] = test_df['Tokens'].str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the Tokenized Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vectorizer model\n",
    "vectorizer = TfidfVectorizer()    # min_df=200, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the corpus to be vectorized\n",
    "tar_col = 'Final_Tokens'    # use cleaned corpus\n",
    "# tar_col = 'Contents'       # use raw corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define testing and training sets\n",
    "X_train = tr_df[tar_col]       # train text to vectorize\n",
    "y_train = tr_df['Category']    # train target labels\n",
    "X_test = test_df[tar_col]      # test text to vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create feature vectors\n",
    "vect = vectorizer.fit(X_train)             # learn the vocabulary and fit idfs\n",
    "X_train_vects = vect.transform(X_train)    # transform the training documents into a document-term matrix\n",
    "X_test_vects = vect.transform(X_test)      # transform the test documents into a document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test_vects.shape, type(X_test_vects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Most Correlated Features by Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of class : category \n",
    "label_to_categ = dict(tr_df[['Class', 'Category']].drop_duplicates().sort_values('Category').values)\n",
    "# Create datarame to hold the correlation results\n",
    "corr_features = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation score for each feature by class\n",
    "for class_label, category in label_to_categ.items():\n",
    "    chi2score = chi2(X_train_vects, y_train == category)[0]     # get correlation scores\n",
    "    wscores = zip(vectorizer.get_feature_names(),chi2score)     # list scores with feature name, instead of feature number\n",
    "    wchi2 = sorted(wscores, key=lambda x:x[1], reverse=True)    # sort the scores in descending order\n",
    "    corr_features[class_label] = list(zip(*wchi2))[0]           # add the sorted list to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top N correlated features by class\n",
    "n = 200\n",
    "corr_head = corr_features.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View most correlated features by class\n",
    "display(corr_head.loc[:, 'C1':'C11'].head(5))\n",
    "display(corr_head.loc[:, 'C12':].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Top-Correlated Features Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of all the top n correlated features\n",
    "top_corr_dict = {c: corr_head[c] for c in corr_head}\n",
    "top_n = set(list_concat(top_corr_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to keep only items found in a reference\n",
    "def keepwords(text, list_of_words):\n",
    "    return [token for token in text if token in list_of_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features not in the top correlation set\n",
    "tr_df['Tokens'] = tr_df['Tokens'].apply(keepwords, args=(top_n,))\n",
    "test_df['Tokens'] = test_df['Tokens'].apply(keepwords, args=(top_n,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df['Final_Tokens'] = tr_df['Tokens'].str.join(' ')\n",
    "test_df['Final_Tokens'] = test_df['Tokens'].str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove docs with k tokens\n",
    "k = 0\n",
    "tr_df = tr_df[tr_df['Tokens'].map(lambda d: len(d)) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of docs removed\n",
    "'{}%'.format(round(100*(num_tr_docs-tr_df.shape[0])/num_tr_docs, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of removed indices\n",
    "rm_inds = set(range(0,num_tr_docs-1)) - set(tuple(tr_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pandas series of training indices for mapping after re-vectorizaton\n",
    "tr_df.reset_index(inplace=True, drop=True)\n",
    "tr_index = pd.Series(tr_df['Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define testing and training sets\n",
    "X_train = tr_df[tar_col]       # train text to vectorize\n",
    "y_train = tr_df['Category']    # train target labels\n",
    "X_test = test_df[tar_col]      # test text to vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create feature vectors\n",
    "vect = vectorizer.fit(X_train)             # learn the vocabulary and fit idfs\n",
    "X_train_vects = vect.transform(X_train)    # transform the training documents into a document-term matrix\n",
    "X_test_vects = vect.transform(X_test)      # transform the test documents into a document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_vects.shape, type(X_train_vects))\n",
    "print(X_test_vects.shape, type(X_test_vects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Dimension Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale\n",
    "(Don't scale tfidf vectors. they are already scaled.)  \n",
    "Scale the feature vectors to mean=0 and unit variance  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the scipy sparse matrices to sparse dataframes \n",
    "# note: this produces NaNs instead of zeroes, which the scaler below doesn't like\n",
    "# train_ftrs = pd.SparseDataFrame(X_train_vects)\n",
    "# test_ftrs = pd.SparseDataFrame(X_test_vects)\n",
    "\n",
    "# convert the scipy sparse matrices to dense dataframes\n",
    "train_temp = pd.DataFrame(X_train_vects.todense())\n",
    "test_temp = pd.DataFrame(X_test_vects.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_temp.shape)\n",
    "print(test_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scaler (mean of 0, variance of 1)\n",
    "# scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit scaler on training set\n",
    "# scaler.fit(train_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scale both the training set and test sets\n",
    "# train_scaled = scaler.transform(train_temp)\n",
    "# test_scaled = scaler.transform(test_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the retained variance (PCA(.95): 95% of the variance is retained)\n",
    "# pca = PCA(.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# Fit PCA on training set\n",
    "# pca.fit(train_ftrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the number of principal compenent vectors (new number of features)\n",
    "# print('number of pca features: ', pca.n_components_)\n",
    "# print('feature reduction of {:.2%}.'.format(pca.n_components_ / train_temp.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Apply PCA to both the training and test sets\n",
    "# train_ftrs = pca.transform(train_ftrs)\n",
    "# test_ftrs = pca.transform(test_ftrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Note: by default, cross_val_score calls either KFold or StratifiedKFold, both of which have shuffle=False,\n",
    "# so the folds are not random. Since my data is arranged by category, I was trying to predict a lot of classes that\n",
    "# the training set had not seen before, and getting worse results. Using ShuffleSplit remedies this by providing\n",
    "# a truly random set.\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=100, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0, solver = 'lbfgs')    # default solver is incredibly slow which is why it was changed to 'lbfgs'\n",
    "]\n",
    "\n",
    "n_cv = 5\n",
    "CV = ShuffleSplit(n_splits=n_cv, test_size=0.3, random_state=0)\n",
    "cv_df = pd.DataFrame(index=range(n_cv * len(models)))\n",
    "entries = []\n",
    "\n",
    "for m in models:\n",
    "    model_name = m.__class__.__name__\n",
    "#     accuracies = cross_val_score(m, train_ftrs, y_train, scoring='accuracy', cv=CV)\n",
    "    accuracies = cross_val_score(m, X_train_vects, y_train, scoring='accuracy', cv=CV)\n",
    "    for fold_idx, value1 in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, value1))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training accuracy by model\n",
    "print('top', n, 'features, total features =', X_train_vects.shape)\n",
    "cv_df.groupby('model_name').accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play sound\n",
    "# winsound.PlaySound('CRCHBELL.WAV', winsound.SND_ASYNC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_end = perf_counter()\n",
    "elapsed_time = t_end - t_start\n",
    "print('Total Elapsed time: %.1f mins' % ((elapsed_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Feature Vectors to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ftrs = pd.concat([tr_df['Category'], train_temp], axis = 1)\n",
    "test_ftrs = pd.concat([test_df['Doc'], test_temp], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ftrs.to_csv('cleaned_training_vectors.csv')\n",
    "test_ftrs.to_csv('cleaned_testing_vectors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_end = perf_counter()\n",
    "elapsed_time = t_end - t_start\n",
    "print('Total Elapsed time: %.1f mins' % ((elapsed_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play sound\n",
    "# winsound.PlaySound('CRCHBELL.WAV', winsound.SND_ASYNC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Feature Vector Matrices to Dataframes\n",
    "(this turned out to be a really inefficient way of doing this. pd.DataFrame(..todense()) is much faster.  \n",
    "also, .tocoo() or .row() removed empty rows, which I didn't want.)  \n",
    "in prep for saving to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert scipy sparse matrix from compressed row format to coordinate format\n",
    "# train_spm = X_train_vects.tocoo()\n",
    "# test_spm = X_test_vects.tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature dataframes\n",
    "# train_ftrs = pd.DataFrame({'Doc':train_spm.row, 'Vocab':train_spm.col, 'TFIDF':train_spm.data, 'Category':0})\n",
    "# test_ftrs = pd.DataFrame({'Doc':test_spm.row, 'Vocab':test_spm.col, 'TFIDF':test_spm.data, 'DocName':''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# Associate the training features with the corresponding category value\n",
    "# for grp, rows in train_ftrs.groupby('Doc'):\n",
    "#     train_ftrs.loc[rows.index, 'Category'] = tr_df.loc[grp,'Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# Associate the testing features with the corresponding document name \n",
    "# for grp, rows in test_ftrs.groupby('Doc'):    \n",
    "#     test_ftrs.loc[rows.index, 'DocName'] = test_df.loc[grp,'Doc']\n",
    "    \n",
    "# # play sound\n",
    "# winsound.PlaySound('CRCHBELL.WAV', winsound.SND_ASYNC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add plus one to the Doc values to reflect the document names starting at 1 ('tr/te_doc_1')\n",
    "# train_ftrs['Doc'] = train_ftrs['Doc'].add(1)\n",
    "# test_ftrs['Doc'] = test_ftrs['Doc'].add(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train: Get random rows and check that the category is correct for doc in both dataframes\n",
    "# tr_rand = train_ftrs.sample(n=3)\n",
    "# l = list(tr_rand['Doc'].apply(lambda x: \"{}{}\".format('tr_doc_', str(x))))\n",
    "# print('tr_df')\n",
    "# display(tr_df.query('Doc == @l'))\n",
    "# print('train_ftrs')\n",
    "# display(tr_rand.sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Get random rows and check that doc and document name match\n",
    "# test_rand = test_ftrs.sample(n=3)\n",
    "# l = list(test_rand['Doc'].apply(lambda x: \"{}{}\".format('te_doc_', str(x))))\n",
    "# print('test_df')\n",
    "# display(test_df.query('Doc == @l'))\n",
    "# print('test_ftrs')\n",
    "# display(test_rand.sort_index())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
