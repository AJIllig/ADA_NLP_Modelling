{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyr)\n",
    "library(data.table)\n",
    "library(foreach)\n",
    "library(lattice)\n",
    "library(ggplot2)\n",
    "library(glmnet)    # lasso and ridge\n",
    "library(class)     # knn\n",
    "library(scales)    # number formatting\n",
    "library(caret)     # confusion matrix\n",
    "library(MASS)      # lda\n",
    "library(e1071)     # svm\n",
    "library(parallelSVM)\n",
    "library(SparseM)\n",
    "library(LiblineaR)\n",
    "library(nnet)      # neural net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to print out the accuracy and macro-f1 score\n",
    "metrics <- function(actual, predicted){\n",
    "    df <- cbind(as.data.frame(actual), as.data.frame(predicted))\n",
    "    names(df) <- c('Actual', 'Predicted')\n",
    "    conf_m <- confusionMatrix(data = factor(df$Predicted, levels = as.character(seq(1:23))),\n",
    "                               reference = factor(df$Actual, ordered = TRUE))\n",
    "    # metrics\n",
    "    tot_acc <- percent(conf_m$overall['Accuracy'])\n",
    "    macro_f1 <- percent(mean(conf_m$byClass[,'F1']))\n",
    "\n",
    "    # view metrics\n",
    "    paste('Accuracy: ',tot_acc,'   ', 'Macro-F1: ', macro_f1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Feature Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the Feature Vector CSVs into Data.Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the index column\n",
    "train <- fread('cleaned_training_vectors.csv', header=TRUE, drop=c(1))\n",
    "test <- fread('cleaned_testing_vectors.csv', header=TRUE, stringsAsFactors=FALSE, drop=c(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the rows of the datatables\n",
    "set.seed(42)\n",
    "train <- train[sample(nrow(train)),]\n",
    "test <- test[sample(nrow(test)),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test and train sets\n",
    "set.seed(42)\n",
    "split_inds <- sample(nrow(train), nrow(train)*(0.8))\n",
    "x_train_split <- as.matrix(train[split_inds, -c(1)])\n",
    "y_train_split <- as.matrix(train$Category[split_inds])\n",
    "x_val_split <- as.matrix(train[-split_inds, -c(1)])\n",
    "y_val_split <- as.matrix(train$Category[-split_inds])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling - Naive bayes\n",
    "Much faster using H20 (v3.ipynb) or Sklearn in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nB_fit <- naiveBayes(Category~., data = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "# nb_preds <- predict(nb_fit, train[-split_inds, -c(1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling - Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference of 30.01597 mins\n"
     ]
    }
   ],
   "source": [
    "# get lambdas\n",
    "NFOLDS <- 5    # k-fold cross-validation\n",
    "ALPHA <- 1\n",
    "t1 <- Sys.time()\n",
    "glmnet_cv <- cv.glmnet(x = Matrix(x_train_split, sparse=TRUE), y = Matrix(y_train_split, sparse=TRUE),\n",
    "                       family = 'multinomial', \n",
    "                        # L1 penalty\n",
    "                        alpha = ALPHA,\n",
    "                        # type of error to use\n",
    "                        type.measure = 'class',\n",
    "                        # cross-validation\n",
    "                        nfolds = NFOLDS,\n",
    "                        # high value is less accurate, but has faster training\n",
    "#                         thresh = 1e-3,\n",
    "                        # again lower number of iterations for faster training\n",
    "#                         maxit = 1e3,\n",
    "                        # since the feature vectors were already standardized in the preprocessing\n",
    "                        standardize = FALSE\n",
    "                        # apply group penalty (multinomial family type only)\n",
    "#                         type.multinomial='grouped'\n",
    "                        )\n",
    "print(difftime(Sys.time(), t1, units = 'min'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict \n",
    "t1 <- Sys.time()\n",
    "glmnet_preds <- predict(glmnet_cv, x_val_split, type = \"class\", s = glmnet_cv$lambda.min)\n",
    "print(difftime(Sys.time(), t1, units = 'min'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=white-space:pre-wrap>'Accuracy:  76.6%     Macro-F1:  75.9%'</span>"
      ],
      "text/latex": [
       "'Accuracy:  76.6\\%     Macro-F1:  75.9\\%'"
      ],
      "text/markdown": [
       "<span style=white-space:pre-wrap>'Accuracy:  76.6%     Macro-F1:  75.9%'</span>"
      ],
      "text/plain": [
       "[1] \"Accuracy:  76.6%     Macro-F1:  75.9%\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "df <- data.frame(y_val_split, glmnet_preds)\n",
    "names(df) <- c('Actual', 'Predicted')\n",
    "conf_m <- confusionMatrix(data = factor(df$Predicted, levels = as.character(seq(1:23))),\n",
    "                           reference = factor(df$Actual, ordered = TRUE))\n",
    "# metrics\n",
    "tot_acc <- percent(conf_m$overall['Accuracy'])\n",
    "macro_f1 <- percent(mean(conf_m$byClass[,'F1']))\n",
    "\n",
    "# view metrics\n",
    "paste('Accuracy: ',tot_acc,'   ', 'Macro-F1: ', macro_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling - LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference of 18.92945 mins\n"
     ]
    }
   ],
   "source": [
    "t1 <- Sys.time()\n",
    "# Fit the model\n",
    "lda_fit <- lda(Category~., data = train[split_inds, -c(1)])\n",
    "print(difftime(Sys.time(), t1, units = 'min'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "lda_preds <- predict(lda_fit, train[-split_inds, -c(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=white-space:pre-wrap>'Accuracy:  78%     Macro-F1:  77.7%'</span>"
      ],
      "text/latex": [
       "'Accuracy:  78\\%     Macro-F1:  77.7\\%'"
      ],
      "text/markdown": [
       "<span style=white-space:pre-wrap>'Accuracy:  78%     Macro-F1:  77.7%'</span>"
      ],
      "text/plain": [
       "[1] \"Accuracy:  78%     Macro-F1:  77.7%\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "df <- data.frame(train$Category[-split_inds], lda_preds)\n",
    "names(df) <- c('Actual', 'Predicted')\n",
    "conf_m <- confusionMatrix(data = factor(df$Predicted, levels = as.character(seq(1:23))),\n",
    "                           reference = factor(df$Actual, ordered = TRUE))\n",
    "# metrics\n",
    "tot_acc <- percent(conf_m$overall['Accuracy'])\n",
    "macro_f1 <- percent(mean(conf_m$byClass[,'F1']))\n",
    "\n",
    "# view metrics\n",
    "paste('Accuracy: ',tot_acc,'   ', 'Macro-F1: ', macro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.lda = function(v, formula, data, cl){\n",
    "    require(MASS)\n",
    "    grps = cut(1:nrow(data), v, labels=FALSE)[sample(1:nrow(data))]\n",
    "    pred = lapply(1:v, function(i, formula, data){\n",
    "        omit = which(grps == i)\n",
    "        z = lda(formula, data=data[-omit,])\n",
    "        predict(z, data[omit,])\n",
    "    }, formula, data)\n",
    "    return(pred)\n",
    "#    wh = unlist(lapply(pred, function(pp)pp$class))\n",
    "#    table(wh,cl[order(grps)])\n",
    "}\n",
    "# https://www.stat.berkeley.edu/~s133/Class2a.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_preds <- cv.lda(2, Category~.,train[split_inds], train[split_inds]$Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "lda_preds <- predict(lda_fit, train[-split_inds, -c(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "df <- data.frame(train$Category[-split_inds], lda_preds)\n",
    "names(df) <- c('Actual', 'Predicted')\n",
    "conf_m <- confusionMatrix(data = factor(df$Predicted, levels = as.character(seq(1:23))),\n",
    "                           reference = factor(df$Actual, ordered = TRUE))\n",
    "# metrics\n",
    "tot_acc <- percent(conf_m$overall['Accuracy'])\n",
    "macro_f1 <- percent(mean(conf_m$byClass[,'F1']))\n",
    "\n",
    "# view metrics\n",
    "paste('Accuracy: ',tot_acc,'   ', 'Macro-F1: ', macro_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling - LinSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"2:20:24 PM\"\n",
      "[1] 0\n",
      "Results for C=0.01 : 0.7060068 accuracy\n",
      "Results for C=0.1 : 0.7502938 accuracy\n",
      "Results for C=1 : 0.7700578 accuracy\n",
      "Results for C=10 : 0.7665092 accuracy\n",
      "Results for C=100 : 0.7519976 accuracy\n",
      "Results for C=1000 : 0.7447241 accuracy\n",
      "Results for C=2000 : 0.7420333 accuracy\n",
      "Best model type is: 0 \n",
      "Best cost is: 1 \n",
      "Best accuracy is: 0.7700578 \n",
      "Time difference of 32.80737 mins\n"
     ]
    }
   ],
   "source": [
    "t1 <- Sys.time()\n",
    "\n",
    "k <- 10 # K-fold cross validation\n",
    "# tryTypes <- c(0,2)\n",
    "tryCosts <- c(.01, .1, 1, 10, 100, 1000, 2000)\n",
    "tryTypes <- 0\n",
    "# tryCosts <- 1\n",
    "bestCost <- NA\n",
    "bestAcc <- 0\n",
    "bestType <- NA\n",
    "\n",
    "# Find the best model with the best cost parameter via k-fold cross-validations\n",
    "for(ty in tryTypes){\n",
    "    print(format(Sys.time(), \"%X\"))\n",
    "    print(ty)\n",
    "    for(co in tryCosts){\n",
    "        svm_fit <- LiblineaR(data=x_train_split, target=y_train_split,\n",
    "                             type=ty, cost=co, cross=k)\n",
    "        cat(\"Results for C=\", co, \" : \", svm_fit, \" accuracy\\n\", sep=\"\")\n",
    "        if(svm_fit > bestAcc){\n",
    "            bestCost <- co\n",
    "            bestAcc <- svm_fit\n",
    "            bestType <- ty\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "cat(\"Best model type is:\", bestType,\"\\n\")\n",
    "cat(\"Best cost is:\", bestCost,\"\\n\")\n",
    "cat(\"Best accuracy is:\", bestAcc,\"\\n\")\n",
    "\n",
    "print(difftime(Sys.time(), t1, units = 'min'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-train best model with best cost value.\n",
    "best <- LiblineaR(data=x_train_split, target=y_train_split, type=bestType, cost=bestCost, bias=1, verbose=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_preds=predict(best, x_val_split, proba=FALSE, decisionValues=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=white-space:pre-wrap>'Accuracy:  77.5%     Macro-F1:  76.6%'</span>"
      ],
      "text/latex": [
       "'Accuracy:  77.5\\%     Macro-F1:  76.6\\%'"
      ],
      "text/markdown": [
       "<span style=white-space:pre-wrap>'Accuracy:  77.5%     Macro-F1:  76.6%'</span>"
      ],
      "text/plain": [
       "[1] \"Accuracy:  77.5%     Macro-F1:  76.6%\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "df <- data.frame(train$Category[-split_inds], svm_preds)\n",
    "names(df) <- c('Actual', 'Predicted')\n",
    "conf_m <- confusionMatrix(data = factor(df$Predicted, levels = as.character(seq(1:23))),\n",
    "                           reference = factor(df$Actual, ordered = TRUE))\n",
    "# metrics\n",
    "tot_acc <- percent(conf_m$overall['Accuracy'])\n",
    "macro_f1 <- percent(mean(conf_m$byClass[,'F1']))\n",
    "\n",
    "# view metrics\n",
    "paste('Accuracy: ',tot_acc,'   ', 'Macro-F1: ', macro_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling - nnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 <- Sys.time()\n",
    "# Fit the model\n",
    "nnet_fit <- nnet::multinom(Category~., data = train[split_inds, -c(1)],\n",
    "                           MaxNWts = 12000, maxit = 100)\n",
    "print(difftime(Sys.time(), t1, units = 'min'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "nnet_preds <-predict(nnet_fit, train[-split_inds, -c(1)], type = 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "df <- data.frame(train$Category[-split_inds], nnet_preds)\n",
    "names(df) <- c('Actual', 'Predicted')\n",
    "conf_m <- confusionMatrix(data = factor(df$Predicted, levels = as.character(seq(1:23))),\n",
    "                           reference = factor(df$Actual, ordered = TRUE))\n",
    "# metrics\n",
    "tot_acc <- percent(conf_m$overall['Accuracy'])\n",
    "macro_f1 <- percent(mean(conf_m$byClass[,'F1']))\n",
    "\n",
    "# view metrics\n",
    "paste('Accuracy: ',tot_acc,'   ', 'Macro-F1: ', macro_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling - K-Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference of 371.6459 mins\n"
     ]
    }
   ],
   "source": [
    "t1 <- Sys.time()\n",
    "n_clust <- round(sqrt(nrow(x_train_split))/2)\n",
    "set.seed(42)\n",
    "knn_preds <- knn(x_train_split, x_test_split, y_train_split, n_clust)\n",
    "print(difftime(Sys.time(), t1, units = 'min'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=white-space:pre-wrap>'Accuracy:  68.2%     Macro-F1:  67.1%'</span>"
      ],
      "text/latex": [
       "'Accuracy:  68.2\\%     Macro-F1:  67.1\\%'"
      ],
      "text/markdown": [
       "<span style=white-space:pre-wrap>'Accuracy:  68.2%     Macro-F1:  67.1%'</span>"
      ],
      "text/plain": [
       "[1] \"Accuracy:  68.2%     Macro-F1:  67.1%\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "df <- data.frame(y_test_split, knn_preds)\n",
    "names(df) <- c('Actual', 'Predicted')\n",
    "conf_m <- confusionMatrix(data = factor(df$Predicted, levels = as.character(seq(1:23))),\n",
    "                           reference = factor(df$Actual, ordered = TRUE))\n",
    "# metrics\n",
    "tot_acc <- percent(conf_m$overall['Accuracy'])\n",
    "macro_f1 <- percent(mean(conf_m$byClass[,'F1']))\n",
    "\n",
    "# view metrics\n",
    "paste('Accuracy: ',tot_acc,'   ', 'Macro-F1: ', macro_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
